{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bigdata_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPiO+o6xDA7CnbDfmQTvZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nrgolden16/BIGDATA_Graduate/blob/main/assignment/bigdata_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-z860L1mbP"
      },
      "source": [
        "# ISLR\n",
        "\n",
        "## 재표본추출 방법(*Resampling Methods*)\n",
        "\n",
        "**재표본추출이란**  \n",
        "* 훈련셋에서 반복적으로 표본을 추출하고 각 표본에 관심있는 모델을 다시 적합하여 적합된 모델에 대해 추가적인 정보를 얻는 것을 말함.  \n",
        "* 훈련 데이터의 다른 서브셋을 사용하여 동일한 통계적 방법을 여러 번 적합하기 때문에 높은 컴퓨팅 능력이 요구됨.   \n",
        "\n",
        "ISLR에서 살펴볼 재표본추출 방법  \n",
        "1. Cross-Validation\n",
        "2. bootstrap  \n",
        "\n",
        "### 교차검증(Cross-Validation)\n",
        "\n",
        "Validation set : model selection에 이용. 하이퍼 파라미터를 튜닝하는데 사용되는 데이터 셋.  \n",
        "\n",
        "보통은 이용할 수 있는 지정된 검증셋이 따로 없는 경우가 많기 때문에 훈련셋들의 일부를 제외하고, 제외된 데이터들에 피팅한 모델을 적용하여 검정오차율을 추정하게 됨.  \n",
        "\n",
        "#### Valdation Set Approach\n",
        "\n",
        "![hold-out](https://t1.daumcdn.net/cfile/tistory/9955CF485E24EFD222)  \n",
        "<출처> 카샤의 만개시기 티스토리\n",
        "\n",
        "- 훈련셋을 임의로 두 부분, 훈련 데이터와 검증셋으로 나누고 훈련데이터로 학습된 모델을 검증셋에 적용하여 검증오차율을 추정하게 됨. 이렇게 임의로 다양한 하이퍼파라미터에 적용한 뒤 가장 작은 검정오차율을 제공하는 모델을 선택하여 테스트셋에 적용하여 test error를 추정하게 됨.  \n",
        "- 데이터를 임의로 훈련셋과 검증셋의 두 부분으로 나누는 과정을 반복한다면 validation error는 randomness가 생기게 됨. (실험할 때마다 결과가 꽤 달라질 수 있음)  \n",
        "- 훈련셋으로만 모델을 적합하므로 validation error를 과대추정하는 경향이 있을 수 있음.  \n",
        "\n",
        "#### LOOCV(Leave-One-Out Cross-Validation)\n",
        "\n",
        "비슷한 크기의 두 subset을 만드는 대신에 하나의 관측치가 검증셋을 사용되고 나머지 관측치로 훈련셋을 구성.  \n",
        "\n",
        "**LOOCV estimate of the test error**\n",
        "\n",
        "$CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{f_{-i}}$\n",
        "\n",
        "\n",
        "**advantage**  \n",
        "- randomness가 없음. 여러 번 수행해도 항상 동일한 결과가 도출.  \n",
        "- 검증셋 기법에 비해 편향이 작음.  \n",
        "\n",
        "**disadvantage**\n",
        "- 많은 연산 시간이 요구됨.  \n",
        "\n",
        "\n",
        "만약, linear model을 적합하는 경우, linear algebra를 적용하여 식을 간단하게 만들 수 있음.\n",
        "\n",
        "$CV_{i} = \\frac{1}{n} \\sum_{i=1}^n (\\frac{y_i - \\hat{y_i}} {1-h_i})^2$\n",
        "\n",
        "위 내용에 대해 추후에 공부하고자 함  \n",
        "링크 : [fast computation](https://robjhyndman.com/hyndsight/loocv-linear-models/)\n",
        "\n",
        "\n",
        "\n",
        "### Permutation tests\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSUY8Ax0CAHt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}